# PURPOSE: Read in ATLAS ITK sim data and convert into filtered form:
# ---------------
#
# INPUT: https://cernbox.cern.ch/index.php/s/CsTC1CQH20IwGOd
# Truth and hit data for ATLAS ITK sim event.
# ---------------
#
# OUTPUT: TrackML format data
# Hit file must have the form:
# hit_id,x,y,z,volume_id,layer_id,module_id
# Truth File must have the form:
# hit_id,particle_id,tx,ty,tz,tpx,tpy,tpz,weight, weight being 0.
# ----------------
#
# DATA SIMPLIFICATIONS:
# Some hits have more than one truth particle, discarding similarly to TrackML simplifications in hepqpr.
# Removing hits generated by end caps.
# FIXME: Output has Ptx Pty Ptz all as Pt. in filtered hits df. can determine absolute values from eta
# FIXME: Output doesnt have real particle charge. I dont believe it's used in hepqpr though
# Secondary vertices removed for the time being.
# ----------------

import numpy as np
import math
import pandas as pd

pd.set_option("display.precision", 18)

# Define Input/Output Dataframes
# Filtered == Output
# Read in unfiltered data first (fixme IO path must be more pythonic)
truth_dataframe = pd.read_csv('/Users/parkerreid/PycharmProjects/ATLASread/Dat/event89712-truth-1.csv')
hits_dataframe = pd.read_csv('/Users/parkerreid/PycharmProjects/ATLASread/Dat/event89712-hits(2).csv')
#Create structure for filtered data
filtered_truth_dataframe = pd.DataFrame({"hit_id":[], "particle_id":[], "tx":[], "ty":[], "tz":[], "tpx":[], "tpy":[]\
                                         ,"tpz":[], "weight":[]})
filtered_hits_dataframe = pd.DataFrame({"hit_id":[], "x":[], "y":[], "z":[], "truth":[], "volume_id":[],\
                                        "layer_id":[], "module_id":[]})
# All of vx,vy...,px,py... are dummies because they aren't actually used.
filtered_particles_dataframe = pd.DataFrame({"particle_id":[], "vx":[], "vy":[], "vz":[], "px":[], "py":[],\
                                        "pz":[], "q":[], "nhits":[]})

print(hits_dataframe.head)

print(list(hits_dataframe.columns.values))

# Layer information, generally hits like +- 10mm on these radial values
# SCT: 39, 99, 160, 228, 291
# TRT: 405, 562 ,762, 1000

layers = [(0,50),(50,120),(120,190),(190,250),(250,350),(350,450),(450,650),(650,850),(850,1100)]

# For each row of data:
# 1. Filter events that do not have a corresponding truth particle
# 2. Determine Radius
count = 0

for index, row in hits_dataframe.iterrows():

    if math.isnan(row["truth1"]) == False and math.isnan(row["truth2"]):
        if np.int(row["truth1"]) <= 5000.0:
            #print(type(np.int(row["truth1"])))
            #print(np.int(row["truth1"]))

            radius = np.sqrt(row['x']**2 + row['y']**2)
            layer = layers.index(list(filter(lambda sl: radius > sl[0] and radius <= sl[1], layers))[0])

            if (np.abs(np.float(row["z"])) < 261 and radius < 120) or (np.abs(np.float(row["z"])) < 1145 and radius > 120):
                #when writing to file, module_id isnt used in hepqpr
                filtered_hits_dataframe.loc[count] = ([row['ID'], row['x'], row['y'], row['z'], row['truth1'], 8, layer, 2])


            count = count + 1



count = 0
# Check for truth particles in thr hit file, that do not correspond to a truth particle in the truth file. remove them
#------------------------------------------------------------------------
truth_ids = []
no_truth_drop = []
for index, row in truth_dataframe.iterrows():
    truth_ids.append(row["truth"])

for pass_index, pass_row in filtered_hits_dataframe.iterrows():

    if pass_row["truth"] not in truth_ids:
        no_truth_drop.append(pass_row["truth"])

filtered_hits_dataframe = filtered_hits_dataframe[~filtered_hits_dataframe['truth'].isin(no_truth_drop)]
count = count + 1
#-----------------------------------------------------------------------

count = 0
# --------- Debug Counters ----
listofcorrect = []
listoffalse = []
# ------------------------------

hit_count = {}


    #for data with the same truth barcode, add new entry to filtered_truth_dataframe
    #Weight in current iteration of code is 0, assigning sequential value
for hit_index, hit_row in filtered_hits_dataframe.iterrows():
    for truth_index, truth_row in truth_dataframe.iterrows():
        if hit_row["truth"] == truth_row["truth"]:
            filtered_truth_dataframe.loc[count] = (hit_row['hit_id'], truth_row['truth'], truth_row['x_prod'],\
                                                   truth_row['y_prod'], truth_row['z_prod'], truth_row['pt'], \
                                                   truth_row['pt'], truth_row['pt'], count*0.01)
            if truth_row['truth'] not in hit_count:
                hit_count[truth_row["truth"]] = 0

            #Add another hit_count to associated particle
            hit_count[truth_row["truth"]] = 1 + hit_count[truth_row["truth"]]

            # Truth File must have the form:
            # hit_id,particle_id,tx,ty,tz,tpx,tpy,tpz,weight, weight being 0.
            count = count+1
            print(count)
            listofcorrect.append(hit_row["truth"])
        listoffalse.append(hit_row["truth"])
count = 0

filtered_truth_dataframe.drop_duplicates(subset='hit_id', keep='first', inplace=True)
 #2nd pass now since we have the duplicate list
drop_list = []
for filtered_hit_index, filtered_hit_row in filtered_hits_dataframe.iterrows():
    if filtered_hit_row["hit_id"] not in filtered_truth_dataframe.values:
        drop_list.append(filtered_hit_row["truth"])


filtered_hits_dataframe = filtered_hits_dataframe[~filtered_hits_dataframe['truth'].isin(drop_list)]

# ----- Particle management. -------------------------------------------------------------
# ------ essentially just require particle ID and number of hits, the rest are dummies for now ---
for filtered_truth_index, filtered_truth_row in filtered_truth_dataframe.iterrows():
    filtered_particles_dataframe.loc[count] = (filtered_truth_row['particle_id'], filtered_truth_row['tx'],
                                                filtered_truth_row['ty'], filtered_truth_row['tz'],
                                                filtered_truth_row['tpx'],
                                                filtered_truth_row['tpy'], filtered_truth_row['tpz'], 1,
                                                hit_count[filtered_truth_row['particle_id']])
    count = count + 1

filtered_particles_dataframe.drop_duplicates(subset='particle_id', keep='first', inplace=True)


'''
# ====================================================================================
#
#  BEGIN PARTICLE SUBSET TESTING: ONLY USE THIS IF YOU PLAN ON TAKING A SMALL TEST SUBSET


#1522 1209

filtered_truth_dataframe_sub = pd.DataFrame({"hit_id":[], "particle_id":[], "tx":[], "ty":[], "tz":[], "tpx":[], "tpy":[]\
                                         ,"tpz":[], "weight":[]})
filtered_hits_dataframe_sub = pd.DataFrame({"hit_id":[], "x":[], "y":[], "z":[], "truth":[], "volume_id":[],\
                                        "layer_id":[], "module_id":[]})

filtered_particles_dataframe_sub = pd.DataFrame({"particle_id":[], "vx":[], "vy":[], "vz":[], "px":[], "py":[],\
                                        "pz":[], "q":[], "nhits":[]})
for drop_index_1, drop_hit in filtered_hits_dataframe.iterrows():
    if drop_hit["truth"] == 1522 or drop_hit["truth"] == 1209:
        filtered_hits_dataframe_sub.loc[drop_index_1] = (drop_hit['hit_id'], drop_hit['x'],\
                                                drop_hit['y'], drop_hit['z'],\
                                                drop_hit['truth'],\
                                                drop_hit['volume_id'], drop_hit['layer_id'],\
                                                drop_hit['module_id'])

for drop_index_2, drop_truth in filtered_truth_dataframe.iterrows():
    if drop_truth["particle_id"] == 1522 or drop_truth["particle_id"] == 1209:
        filtered_truth_dataframe_sub.loc[drop_index_2] = (drop_truth['hit_id'], drop_truth['particle_id'], drop_truth['tx'],\
                                                drop_truth['ty'], drop_truth['tz'],\
                                                drop_truth['tpx'],\
                                                drop_truth['tpy'], drop_truth['tpz'],\
                                                drop_truth['weight'])
for drop_index_3, drop_particle in filtered_particles_dataframe.iterrows():
    if drop_particle["particle_id"] == 1522 or drop_particle["particle_id"] == 1209:
        filtered_particles_dataframe_sub.loc[drop_index_3] = (drop_particle['particle_id'], drop_particle['vx'],\
                                                drop_particle['vy'], drop_particle['vz'],\
                                                drop_particle['px'],\
                                                drop_particle['py'], drop_particle['pz'],\
                                                drop_particle['q'],  drop_particle['nhits'])


#
#  END PARTICLE SUBSET TESTING:
#
# ====================================================================================
'''
listofmissing =set(listoffalse).difference(set(listofcorrect))


# Drop the truth particle associated with the hit
#filtered_hits_dataframe.drop(columns=["truth"])

#Reiterate that....
#Hit file must have the form:
#hit_id,x,y,z,volume_id,layer_id,module_id

# Truth File must have the form:
# hit_id,particle_id,tx,ty,tz,tpx,tpy,tpz,weight, weight being 0

print(filtered_particles_dataframe.head())
filtered_hits_dataframe.to_csv("Dat/ATLAS_TrackML-event89712-hits.csv", index=False, float_format='%17.2f')
filtered_truth_dataframe.to_csv("Dat/ATLAS_TrackML-event89712-truth.csv", index=False, float_format='%17.2f')
filtered_particles_dataframe.to_csv("Dat/ATLAS_TrackML-event89712-particles.csv", index=False, float_format='%9.2f')
